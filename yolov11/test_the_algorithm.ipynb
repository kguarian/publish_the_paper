{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from math import ceil, sqrt\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test directory\n",
    "test_dir = \"/Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test\"\n",
    "output_collage = \"collage_with_boxes.png\"\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(\n",
    "    \"/Users/kenton/HOME/coding/python/publish_the_paper/runs/detect/train50/weights/best.pt\"\n",
    ")\n",
    "\n",
    "# Get all image files in the directory\n",
    "all_images = [\n",
    "    os.path.join(test_dir, f)\n",
    "    for f in os.listdir(test_dir)\n",
    "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "# Randomly select 100 images (or fewer if there are not enough images)\n",
    "random_images = random.sample(all_images, min(len(all_images), 100))\n",
    "\n",
    "# Optional: Load a font for better text rendering\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=16)  # Use a font installed on your system\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_183039.png: 64x416 (no detections), 22.0ms\n",
      "Speed: 3.9ms preprocess, 22.0ms inference, 4.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_99730.png: 64x416 1 burst, 8.4ms\n",
      "Speed: 0.3ms preprocess, 8.4ms inference, 4.1ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98392.png: 64x416 2 non-bursts, 1 burst, 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_96493.png: 64x416 2 non-bursts, 1 burst, 6.1ms\n",
      "Speed: 0.2ms preprocess, 6.1ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98326.png: 64x416 2 non-bursts, 1 burst, 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94677.png: 64x416 2 non-bursts, 1 burst, 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_91929.png: 64x416 2 non-bursts, 1 burst, 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92464.png: 64x416 1 burst, 7.0ms\n",
      "Speed: 0.2ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_191173.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.3ms preprocess, 6.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_195693.png: 64x416 (no detections), 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186911.png: 64x416 (no detections), 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90187.png: 64x416 2 non-bursts, 1 burst, 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_193089.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_99024.png: 64x416 2 non-bursts, 1 burst, 6.5ms\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92479.png: 64x416 2 non-bursts, 1 burst, 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_96010.png: 64x416 1 non-burst, 1 burst, 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94090.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_196279.png: 64x416 (no detections), 6.8ms\n",
      "Speed: 0.3ms preprocess, 6.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_193739.png: 64x416 (no detections), 6.7ms\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_97247.png: 64x416 2 non-bursts, 1 burst, 6.6ms\n",
      "Speed: 0.3ms preprocess, 6.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_180847.png: 64x416 (no detections), 6.4ms\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_187455.png: 64x416 (no detections), 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_93767.png: 64x416 1 non-burst, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98749.png: 64x416 2 non-bursts, 1 burst, 6.4ms\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_95515.png: 64x416 2 non-bursts, 1 burst, 6.9ms\n",
      "Speed: 0.4ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_95249.png: 64x416 1 burst, 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92768.png: 64x416 1 burst, 6.3ms\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186585.png: 64x416 (no detections), 6.0ms\n",
      "Speed: 0.2ms preprocess, 6.0ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_196403.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94962.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_192593.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94971.png: 64x416 2 non-bursts, 1 burst, 5.8ms\n",
      "Speed: 0.3ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92172.png: 64x416 1 non-burst, 1 burst, 6.5ms\n",
      "Speed: 0.3ms preprocess, 6.5ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_196539.png: 64x416 (no detections), 6.4ms\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_181493.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_91935.png: 64x416 2 non-bursts, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186769.png: 64x416 (no detections), 5.4ms\n",
      "Speed: 0.2ms preprocess, 5.4ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_97876.png: 64x416 2 non-bursts, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_195865.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_182133.png: 64x416 (no detections), 6.0ms\n",
      "Speed: 0.2ms preprocess, 6.0ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_197665.png: 64x416 (no detections), 6.7ms\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_190635.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92869.png: 64x416 1 non-burst, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_190475.png: 64x416 (no detections), 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_93262.png: 64x416 2 non-bursts, 1 burst, 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_188507.png: 64x416 (no detections), 5.8ms\n",
      "Speed: 0.3ms preprocess, 5.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_197001.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_192805.png: 64x416 (no detections), 6.4ms\n",
      "Speed: 0.2ms preprocess, 6.4ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94300.png: 64x416 1 non-burst, 1 burst, 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_190619.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_99660.png: 64x416 (no detections), 5.6ms\n",
      "Speed: 0.2ms preprocess, 5.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_190315.png: 64x416 (no detections), 5.3ms\n",
      "Speed: 0.2ms preprocess, 5.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_192021.png: 64x416 (no detections), 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90546.png: 64x416 2 non-bursts, 1 burst, 6.1ms\n",
      "Speed: 0.2ms preprocess, 6.1ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_185383.png: 64x416 (no detections), 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_95018.png: 64x416 2 non-bursts, 1 burst, 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94547.png: 64x416 2 non-bursts, 6.8ms\n",
      "Speed: 0.2ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_181657.png: 64x416 (no detections), 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90301.png: 64x416 2 non-bursts, 1 burst, 5.4ms\n",
      "Speed: 0.2ms preprocess, 5.4ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_95298.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_94861.png: 64x416 2 non-bursts, 1 burst, 5.5ms\n",
      "Speed: 0.2ms preprocess, 5.5ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_187755.png: 64x416 (no detections), 6.5ms\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_192879.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90544.png: 64x416 2 non-bursts, 1 burst, 6.2ms\n",
      "Speed: 0.3ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_193207.png: 64x416 (no detections), 6.0ms\n",
      "Speed: 0.2ms preprocess, 6.0ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_97490.png: 64x416 2 non-bursts, 1 burst, 5.2ms\n",
      "Speed: 0.2ms preprocess, 5.2ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_185565.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_180493.png: 64x416 (no detections), 5.5ms\n",
      "Speed: 0.2ms preprocess, 5.5ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_197371.png: 64x416 (no detections), 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_93030.png: 64x416 2 non-bursts, 1 burst, 6.8ms\n",
      "Speed: 0.3ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186489.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98439.png: 64x416 2 non-bursts, 1 burst, 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_183043.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_189387.png: 64x416 (no detections), 5.7ms\n",
      "Speed: 0.2ms preprocess, 5.7ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_197203.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90754.png: 64x416 2 non-bursts, 1 burst, 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_196437.png: 64x416 (no detections), 7.3ms\n",
      "Speed: 0.3ms preprocess, 7.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_195331.png: 64x416 (no detections), 7.7ms\n",
      "Speed: 0.3ms preprocess, 7.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_185199.png: 64x416 (no detections), 7.2ms\n",
      "Speed: 0.2ms preprocess, 7.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186605.png: 64x416 (no detections), 6.7ms\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_92357.png: 64x416 2 non-bursts, 1 burst, 6.7ms\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_182287.png: 64x416 (no detections), 6.7ms\n",
      "Speed: 0.3ms preprocess, 6.7ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_90369.png: 64x416 (no detections), 6.9ms\n",
      "Speed: 0.3ms preprocess, 6.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_91871.png: 64x416 2 non-bursts, 1 burst, 6.7ms\n",
      "Speed: 0.2ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_191179.png: 64x416 (no detections), 6.6ms\n",
      "Speed: 0.2ms preprocess, 6.6ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_192397.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_193557.png: 64x416 (no detections), 6.0ms\n",
      "Speed: 0.2ms preprocess, 6.0ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98676.png: 64x416 2 non-bursts, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_198249.png: 64x416 (no detections), 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_185171.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_183675.png: 64x416 (no detections), 6.2ms\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_98618.png: 64x416 1 non-burst, 1 burst, 6.5ms\n",
      "Speed: 0.2ms preprocess, 6.5ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_186297.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_93521.png: 64x416 2 non-bursts, 1 burst, 6.0ms\n",
      "Speed: 0.2ms preprocess, 6.0ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_99678.png: 64x416 2 non-bursts, 1 burst, 5.8ms\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_95425.png: 64x416 2 non-bursts, 1 burst, 5.9ms\n",
      "Speed: 0.2ms preprocess, 5.9ms inference, 0.3ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_194129.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.2ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_185721.png: 64x416 (no detections), 6.3ms\n",
      "Speed: 0.3ms preprocess, 6.3ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_96012.png: 64x416 2 non-bursts, 1 burst, 6.1ms\n",
      "Speed: 0.3ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 64, 416)\n",
      "\n",
      "image 1/1 /Users/kenton/HOME/coding/python/publish_the_paper/yolov11/dataset_tinkering/training_data_pn/images/test/sig_197157.png: 64x416 (no detections), 7.5ms\n",
      "Speed: 0.3ms preprocess, 7.5ms inference, 0.2ms postprocess per image at shape (1, 3, 64, 416)\n",
      "Collage saved to collage_with_boxes.png\n"
     ]
    }
   ],
   "source": [
    "# Annotate each selected image\n",
    "annotated_images = []\n",
    "for image_path in random_images:\n",
    "    # Predict results for the image\n",
    "    results = model.predict(source=image_path, conf=0.8)\n",
    "\n",
    "    # Load the image using PIL\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Process model predictions\n",
    "    for r in results:\n",
    "        for box in r.boxes.data:\n",
    "            # Extract bounding box and class information\n",
    "            x1, y1, x2, y2, confidence, class_id = box.tolist()\n",
    "            class_name = model.names[int(class_id)]  # Get class name using model's class names\n",
    "\n",
    "            # Draw the bounding box\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "\n",
    "            # Create a label\n",
    "            label = f\"{class_name} ({confidence:.2f})\"\n",
    "\n",
    "            # Draw label inside the bounding box\n",
    "            text_bbox = draw.textbbox((x1, y1), label, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            # Position text inside the bounding box, adjusted to fit\n",
    "            label_x = max(x1, 0) + 2\n",
    "            label_y = max(y1, 0) + 2\n",
    "\n",
    "            # Draw label background and text\n",
    "            draw.rectangle(\n",
    "                [label_x, label_y, label_x + text_width, label_y + text_height],\n",
    "                fill=\"red\",\n",
    "            )\n",
    "            draw.text((label_x, label_y), label, fill=\"white\", font=font)\n",
    "\n",
    "    # Resize the image to a fixed size for the collage\n",
    "    resized_image = image.resize((200, 200))  # Adjust size as needed\n",
    "    annotated_images.append(resized_image)\n",
    "\n",
    "# Determine collage dimensions (square layout)\n",
    "collage_size = ceil(sqrt(len(annotated_images)))  # Closest square size\n",
    "collage_width = collage_size * 200\n",
    "collage_height = collage_size * 200\n",
    "\n",
    "# Create the blank collage canvas\n",
    "collage = Image.new(\"RGB\", (collage_width, collage_height), color=\"white\")\n",
    "\n",
    "# Paste each image into the collage\n",
    "for i, annotated_image in enumerate(annotated_images):\n",
    "    row = i // collage_size\n",
    "    col = i % collage_size\n",
    "    x_offset = col * 200\n",
    "    y_offset = row * 200\n",
    "    collage.paste(annotated_image, (x_offset, y_offset))\n",
    "\n",
    "# Save the collage\n",
    "collage.save(output_collage)\n",
    "print(f\"Collage saved to {output_collage}\")\n",
    "collage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
